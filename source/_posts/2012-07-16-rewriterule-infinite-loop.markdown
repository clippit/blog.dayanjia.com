---
layout: post
title: "一条RewriteRule引发的血案"
date: 2012-07-16 22:51
comments: true
categories: 
 - 雕虫小技
---

这是一则拖了将近两个月的问题。事情的起因是我从某天开始发现服务器上的Apache进程`httpd`经常会莫名其妙地吃光所有的内存和Swap，然后因为内存占用过多被Kernel杀死。由于系统内存在多个httpd进程，于是这个现象便周而复始地发生，把整个服务器系统弄得很慢很卡。

由于以前没有相关经验，而这个问题的发生也存在一定的随机性，再加上服务器上跑着好几个虚拟主机，因此一直没有办法查出原因所在。在翻遍了Google，造访了[ServerFault](http://serverfault.com/questions/383291/apache-out-of-memory)后，仍然无解，于是这个问题就毫无头绪地搁置了许久。直到最近利用迁移服务器的机会，终于发现了线索。

<!--more-->

## [OOM Killer](http://linux-mm.org/OOM_Killer)

OOM Killer是Linux的一项保护机制，旨在内存不够用的时候杀掉一些进程，以保证系统能够稳定运行。OOM Killer在选择杀掉哪个进程的时候，会应用一个算法，一般来说消耗内存最大的那个进程是难以幸免的。在OOM Killer发生作用时，会向系统日志写入相关的信息。在我原先的一台2.6内核的系统上，会出现[类似这样的日志](http://pastebin.com/bszy9ahq)，而在最近的3.4内核中，会出现[如这样的日志信息](http://pastebin.com/bAK9rQye)。虽然信息量不尽相同，但是结果都是一样的，那就是一个httpd进程消耗了几乎所有的内存，然后被杀死。如果使用`top`命令实时监控的话，也会看到相同的现象。

## 如何排查？

可以获得的信息基本就是一段段OOM Killer的日志，和莫名其妙突然小宇宙爆发的httpd。翻阅了Apache、PHP、MySQL的各项日志后，也依然没有任何可疑的迹象。服务器上运行的虚拟主机有好几个，也无法定位到底是哪个和问题有关。何况问题的发生完全是随机的（应该跟访问有关），无法知道到底什么时候会内存泄漏，也就难以对比排除因素。万年小学生说，真相只有一个，那么真相呢？

前段时间正好入手了一台Linode，准备把原先的数据都迁移过去。这是一个解决问题的好时机。当范围缩小后，排查应该会容易许多。

## 目标锁定

因为不知道问题是如何触发的，每做一项操作就要等待一段时间，检查是否有内存泄漏的问题发生。